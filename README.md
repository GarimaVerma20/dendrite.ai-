# Dendrite.ai
## Problem Statement
This assignment is to parse the JSON file provided(algoparams_from_ui) and kick off in sequence the following machine learning steps programmatically like feature handling, feature generation and model building using Grid search after parsing hyper parameters. 

Used scikit-learn-compatible machine learning pipeline that automates key stages of **feature handling**, **feature reduction**, and **model selection**.

## Approach 

- The goal was to:

   - Parse this JSON file

   - Execute all Machine Learning steps in sequence

   - Dynamically adapt to different configurations
 
   - Scikit-learn-compatible pipeline architecture
### Key Features
- #### 1. Feature Handling
  
   - Handles both numerical and textual data based on defined strategies. 
   
   - **Numerical Features:** Supports imputation using mean values or custom constants. 
   
   - **Text Features:** Supports hashing vectorization.
 
'''     FeatureHandlerTransformer
â”‚
â”œâ”€â”€ For Each Feature in JSON:
â”‚   â””â”€â”€ If "is_selected" is True:
â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       â”‚ Feature Type? â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚              â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     â”‚ Numerical       â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    â”‚ Missing Handling   â”‚
â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    â”‚ "Average of values"â”‚â”€â”€â–º Fill NaNs with mean
â”‚    â”‚ "custom"           â”‚â”€â”€â–º Fill NaNs with given value
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     â”‚ Text            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    â”‚ Missing Handling     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚       Fill NaNs with "missing_text"
â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    â”‚ Text Encoding (optional)   â”‚
â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    â”‚ "Tokenize and hash"        â”‚â”€â”€â–º Apply HashingVectorizer  
â”‚    â”‚                            â”‚     â†’ Creates N hashed columns  
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â””â”€â”€â–º Output: Transformed DataFrame (with numeric and/or hashed columns)
'''
   
- #### 2. Feature Reduction
  
   - **No Reduction:** Skips this step. 
   
   - **Correlation with Target:** Selects top k features most correlated with the target. 
   
   - **Tree-Based:** Uses feature importance from a Random Forest to select top k features. 
   
   - **PCA:** Applies Principal Component Analysis to keep top n components.

     <pre> ### ğŸ”» Feature Reduction Logic ``` FeatureReductionTransformer â”‚ â”œâ”€â”€ Read "reduction_method" from JSON â”‚ â”œâ”€â”€ If "No Reduction": â”‚ â””â”€â”€ Return input features unchanged â”‚ â”œâ”€â”€ If "Correlation with Target": â”‚ â”œâ”€â”€ Compute correlation of each feature with y â”‚ â””â”€â”€ Select top K most correlated features â”‚ â”œâ”€â”€ If "Tree-Based": â”‚ â”œâ”€â”€ Train RandomForest using input X and y â”‚ â”œâ”€â”€ Extract feature importances â”‚ â””â”€â”€ Select top K important features â”‚ â”œâ”€â”€ If "PCA": â”‚ â”œâ”€â”€ Standardize input features â”‚ â”œâ”€â”€ Fit PCA on standardized X â”‚ â””â”€â”€ Keep top N principal components â”‚ â””â”€â”€â–º Output: Reduced Feature Set (X_transformed) ``` </pre>

'''     FeatureReductionTransformer
â”‚
â”œâ”€â”€ Read "reduction_method" from JSON
â”‚
â”œâ”€â”€ If "No Reduction":
â”‚   â””â”€â”€ Return input features unchanged
â”‚
â”œâ”€â”€ If "Correlation with Target":
â”‚   â”œâ”€â”€ Compute correlation of each feature with y
â”‚   â””â”€â”€ Select top K most correlated features
â”‚
â”œâ”€â”€ If "Tree-Based":
â”‚   â”œâ”€â”€ Train RandomForest using input X and y
â”‚   â”œâ”€â”€ Extract feature importances
â”‚   â””â”€â”€ Select top K important features
â”‚
â”œâ”€â”€ If "PCA":
â”‚   â”œâ”€â”€ Standardize input features
â”‚   â”œâ”€â”€ Fit PCA on standardized X
â”‚   â””â”€â”€ Keep top N principal components
â”‚
â””â”€â”€â–º Output: Reduced Feature Set (X_transformed)
'''

- #### 3. Model Selection with Grid Search
  
   - Automatically selects the best model from a predefined list. 
   
   - Supports both regression and classification tasks, based on the prediction_type from json. 
   
   - Evaluates multiple models (like Linear Regression, Decision Tree, Random Forest, etc.) along with their hyperparameter grids. 
   
   - Automatically runs GridSearchCV with user-defined hyperparameters. 
   
   - Returns the best model, its parameters, and evaluation metrics.
 
'''     ModelSelectionWithGridSearch
â”‚
â”œâ”€â”€ Read model list & hyperparameter grid from JSON
â”‚
â”œâ”€â”€ For each model in list:
â”‚   â”œâ”€â”€ Build GridSearchCV object
â”‚   â”œâ”€â”€ Perform cross-validation
â”‚   â””â”€â”€ Store best estimator & score
â”‚
â”œâ”€â”€ After all models:
â”‚   â””â”€â”€ Pick model with best validation score
â”‚
â””â”€â”€â–º Output:
    â”œâ”€â”€ Best estimator (model)
    â”œâ”€â”€ Best parameters
    â””â”€â”€ Evaluation metrics (e.g., RMSE, Accuracy)
'''

- ## Inputs
  
   - **DataFrame X:** Feature set as a pandas DataFrame 
   
   - **Target y:** Target values  
   
   - **Steps :** 
   
       - **feature_handling:** Specifies treatment strategy per feature (e.g., imputation, hashing) 
         
       - **feature_reduction:** Defines parameters for feature selection 
         
       - **model_selection:** Lists models and hyperparameters for grid search 


- ## Technologies Used
   - Python 
   
   - scikit-learn  
   
   - pandas, numpy  
   
   - HashingVectorizer 
   
   - GridSearchCV 
   
   - JSON for configuration         


**"Given the ** Iris dataset and a config that uses tree-based feature reduction and Random Forest with tuning, the pipeline outputs the best-performing model with best score 0.96."**
